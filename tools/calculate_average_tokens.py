# File: tools/calculate_average_tokens.py
import argparse
import json
import base64
import sys
import os
from PIL import Image
from io import BytesIO

# Add the parent directory to sys.path to import benchmark.oaitokenizer
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from benchmark.oaitokenizer import num_tokens_from_text

# --- Reused constants and functions from generate_input_prompt.py ---
IMG_BASE_TOKENS_PER_IMG = 85
IMG_HQ_TOKENS_PER_TILE = 170
IMG_TILE_SIZE = 512

def get_base64_img_dimensions(base64_image: str) -> tuple[int, int] | None:
    """
    Return width and height of a base64 image.
    """
    try:
        img = Image.open(BytesIO(base64.b64decode(base64_image)))
        return img.size
    except Exception as e:
        print(f"Warning: Error decoding image or calculating dimensions: {e}")
        return None

def calc_num_img_patches(width: int, height: int) -> int:
    max_side = max(width, height)
    scaling_factor = min(1, 2048 / max_side)
    scaled_width, scaled_height = int(width * scaling_factor), int(height * scaling_factor)

    min_side = min(scaled_width, scaled_height)
    scaling_factor = min(1, 768 / min_side)
    scaled_width, scaled_height = int(scaled_width * scaling_factor), int(scaled_height * scaling_factor)

    num_width_tiles = scaled_width // IMG_TILE_SIZE + int(scaled_width % IMG_TILE_SIZE > 0)
    num_height_tiles = scaled_height // IMG_TILE_SIZE + int(scaled_height % IMG_TILE_SIZE > 0)
    return num_width_tiles * num_height_tiles

def get_image_token_count_from_base64(base64_image: str, quality_mode: str) -> int:
    """
    Calculate the token count for an image based on its base64 data and quality.
    """
    assert quality_mode in ["high", "low"]
    if quality_mode == "low":
        return IMG_BASE_TOKENS_PER_IMG
    else:
        dimensions = get_base64_img_dimensions(base64_image)
        if dimensions:
            width, height = dimensions
            tiles_per_img = calc_num_img_patches(width, height)
            return IMG_BASE_TOKENS_PER_IMG + tiles_per_img * IMG_HQ_TOKENS_PER_TILE
        else:
            print("Warning: Could not get image dimensions, returning base token count.")
            return IMG_BASE_TOKENS_PER_IMG
# --- End of reused code ---

def calculate_tokens_from_json(json_file_path: str) -> tuple[float, float]:
    """
    Calculates the average text and image tokens per prompt from a JSON file.

    Args:
        json_file_path: Path to the input JSON file generated by generate_input_prompt.py.

    Returns:
        A tuple containing (average_text_tokens, average_image_tokens).
        Returns (0.0, 0.0) if the file cannot be processed or contains no prompts.
    """
    try:
        with open(json_file_path, 'r') as f:
            prompts = json.load(f)
    except FileNotFoundError:
        print(f"Error: File not found at '{json_file_path}'")
        return 0.0, 0.0
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{json_file_path}'")
        return 0.0, 0.0
    except Exception as e:
        print(f"An unexpected error occurred while reading the file: {e}")
        return 0.0, 0.0

    total_text_tokens = 0
    total_image_tokens = 0
    num_prompts = len(prompts)

    if num_prompts == 0:
        print("Warning: The JSON file contains no prompts.")
        return 0.0, 0.0

    for prompt in prompts:
        prompt_text_tokens = 0
        prompt_image_tokens = 0
        # Find the user message (usually the last one)
        user_message = next((msg for msg in reversed(prompt) if msg.get("role") == "user"), None)

        if user_message and isinstance(user_message.get("content"), list):
            for content_item in user_message["content"]:
                if content_item.get("type") == "text":
                    text = content_item.get("text", "")
                    # Assuming gpt-4o tokenizer, as used in the generation script
                    prompt_text_tokens += num_tokens_from_text(text, "gpt-4o")
                elif content_item.get("type") == "image_url":
                    image_url_data = content_item.get("image_url", {})
                    b64_prefix = "data:image/jpeg;base64,"
                    base64_image_data = image_url_data.get("url", "")
                    if base64_image_data.startswith(b64_prefix):
                        base64_image = base64_image_data[len(b64_prefix):]
                        quality = image_url_data.get("detail", "high") # Default to high if not specified
                        prompt_image_tokens += get_image_token_count_from_base64(base64_image, quality)
                    else:
                         print(f"Warning: Skipping image entry with unexpected URL format: {base64_image_data[:50]}...")

        total_text_tokens += prompt_text_tokens
        total_image_tokens += prompt_image_tokens

    avg_text_tokens = total_text_tokens / num_prompts if num_prompts > 0 else 0.0
    avg_image_tokens = total_image_tokens / num_prompts if num_prompts > 0 else 0.0

    return avg_text_tokens, avg_image_tokens

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Calculate average input text and image tokens from a prompt JSON file."
    )
    parser.add_argument(
        "--input-file",
        type=str,
        required=True,
        help="Path to the JSON file generated by generate_input_prompt.py."
    )
    args = parser.parse_args()

    avg_text, avg_image = calculate_tokens_from_json(args.input_file)

    if avg_text is not None and avg_image is not None:
        print(f"Results for: {args.input_file}")
        print(f"Average Input Text Tokens per Prompt: {avg_text:.2f}")
        print(f"Average Input Image Tokens per Prompt: {avg_image:.2f}")